{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.summary.summary_iterator import summary_iterator\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Directory containing the TensorBoard files\n",
    "base_dir = \"...\"\n",
    "config = \"1010_xsub120_policy\"\n",
    "\n",
    "if not os.path.exists(config):\n",
    "    os.makedirs(config)\n",
    "    print(f\"Directory '{config}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Directory '{config}' already exists.\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load data from tensorboard file\n",
    "common = [\"act\", \"att_lay\", \"conv_lay\", \"drop_prob\", \"init_lay\"]\n",
    "input_stream = [\"blocks_in\", \"depth_in\", \"stride_in\", \"scale_in\", \"temp_win_in\", \"graph_dist_in\", \"reduct_ratio_in\"]\n",
    "main_stream = [\"blocks_main\", \"depth_main\", \"graph_dist_main\", \"shrinkage_main\", \"residual_main\", \"adaptive_main\"]\n",
    "\n",
    "all_values = []\n",
    "\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for dir_name in dirs:\n",
    "        if dir_name.startswith(\"_Parameters_\"):\n",
    "            dir_path = os.path.join(root, dir_name)\n",
    "            files = os.listdir(dir_path)\n",
    "            # Loop over each file\n",
    "            for file in files:\n",
    "                # Load TensorBoard file\n",
    "                file_path = os.path.join(dir_path, file)\n",
    "                # print(f\"Processing file: {file_path}\")\n",
    "\n",
    "                # Load the TensorBoard logs\n",
    "                for event in summary_iterator(file_path):\n",
    "                    last_underscore_index = dir_name.rfind(\"_\")\n",
    "                    if last_underscore_index != -1:\n",
    "                        act_value = dir_name[last_underscore_index + 1:]\n",
    "                    else:\n",
    "                        act_value = \"Unknown\"\n",
    "                    for value in event.summary.value:\n",
    "                        all_values.append((value.tag, act_value, value.simple_value))\n",
    "\n",
    "# Sort\n",
    "sorted_values = sorted(all_values, key=lambda x: (x[0], x[1]))\n",
    "\n",
    "prev_val = None\n",
    "index = 0\n",
    "# Write sorted values to a file\n",
    "with open(\"./{}/{}_sorted.txt\".format(config, config), \"w\") as f:\n",
    "    for tag, act_value, simple_value in sorted_values:\n",
    "        if act_value != prev_val:\n",
    "            index = 0\n",
    "            prev_val = act_value\n",
    "            num_values = int(sum(1 for tager, _, _ in sorted_values if tager == tag) / 1)\n",
    "\n",
    "        if index == 0:\n",
    "\n",
    "            f.write(f\"{tag}, {act_value}, x=0, y={1/num_values}\\n\")\n",
    "            f.write(f\"{tag}, {act_value}, x=1, y={simple_value}\\n\")\n",
    "        elif index == 1:\n",
    "            f.write(f\"{tag}, {act_value}, x=2, y={simple_value}\\n\")\n",
    "        elif index == 2:\n",
    "            f.write(f\"{tag}, {act_value}, x=3, y={simple_value}\\n\")\n",
    "\n",
    "         # Increment index for the next value\n",
    "        index += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting\n",
    "\n",
    "\n",
    "# Read data from the text file\n",
    "data_file = \".../{}/{}_sorted.txt\".format(config, config)\n",
    "with open(data_file, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Parse the data\n",
    "grouped_data = {}\n",
    "for line in lines:\n",
    "    parts = line.split(\", \")\n",
    "    tag = parts[0]\n",
    "    act_value = parts[1]\n",
    "    x, y = int(parts[2].split(\"=\")[1]), float(parts[3].split(\"=\")[1])\n",
    "    key = (tag, act_value)\n",
    "    if key not in grouped_data:\n",
    "        grouped_data[key] = {'x': [], 'y': []}\n",
    "    grouped_data[key]['x'].append(x)\n",
    "    grouped_data[key]['y'].append(round(y, 8))\n",
    "\n",
    "# Define groups\n",
    "common = [\"act\", \"att_lay\", \"conv_lay\", \"drop_prob\", \"init_lay\"]\n",
    "common_names =  [\"Activation layer\", \"Attention layer\", \"Conv. layer type\", \"Dropout probability\", \"Init layer size\"]\n",
    "\n",
    "input_stream = [\"blocks_in\", \"depth_in\", \"stride_in\", \"scale_in\", \"temp_win_in\", \"graph_dist_in\", \"reduct_ratio_in\"]\n",
    "input_stream_names = [\"Blocks in\", \"Depth in\", \"Stride in\", \"Scaling factor\", \"Temporal window\", \"Graph distance\", \"Reduction factor\"]\n",
    "\n",
    "main_stream = [\"blocks_main\", \"depth_main\", \"graph_dist_main\", \"shrinkage_main\", \"residual_main\", \"adaptive_main\"]\n",
    "main_stream_names = [\"Blocks main\", \"Depth main\", \"Graph distance\", \"Shrinkage\", \"Residual layer\", \"Adaptive\"]\n",
    "\n",
    "optimizer = [\"lr\", \"optimizers\", \"weight_decay\", \"momentum\", \"batch_size\"]\n",
    "optimizer_names = [\"Learning rate\", \"Optimizer\", \"Weight decay\", \"Momentum\", \"Batch size\"]\n",
    "\n",
    "# Initialize dicts\n",
    "group_data = {\n",
    "    \"Common\": [common, common_names],\n",
    "    \"Input Stream\": [input_stream, input_stream_names],\n",
    "    \"Main Stream\": [main_stream, main_stream_names],\n",
    "    \"Optimizer\": [optimizer, optimizer_names]\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting for each group and one pdf\n",
    "markers = ['o', 's', 'D', '^', 'v', '*', 'x']\n",
    "font = {'fontname': 'Times New Roman', 'size': 14}\n",
    "font_bigger = {'fontname': 'Times New Roman', 'size': 16}\n",
    "for group_name, group_keys in group_data.items():\n",
    "    plt.figure(figsize=(18, 4))\n",
    "    plt.suptitle(f'Policy values of the {group_name} group', **font_bigger)\n",
    "    num_subplots = len(group_keys[0])\n",
    "    subplot_index = 1\n",
    "    for i, key in enumerate(group_keys[0], start=1):\n",
    "        plt.subplot(1, num_subplots, i)\n",
    "        plt.xlabel('# Controller update', **font)\n",
    "        # plt.ylabel('Probability')\n",
    "\n",
    "        if i == 1:\n",
    "            plt.ylabel('Probability', **font)\n",
    "        else:\n",
    "            plt.ylabel('')\n",
    "\n",
    "        plt.xticks([0, 1, 2, 3])\n",
    "        plt.title(f'{str(group_keys[1][i-1])}', **font)\n",
    "        plt.grid(True, linewidth=0.25)\n",
    "\n",
    "        index_marker = 0\n",
    "        for i, ((tag, act), values) in enumerate(grouped_data.items()):\n",
    "\n",
    "            if key in tag:\n",
    "                # plt.scatter(values['x'], values['y'])\n",
    "                # Calculate step locations with a margin of 10%\n",
    "                # step_locations = [values['x'][j] + 0.1 * (values['x'][j + 1] - values['x'][j]) for j in range(len(values['x']) - 1)]\n",
    "\n",
    "                plt.step(values['x'], values['y'], where=\"post\", label=f'{act}', marker=markers[index_marker])\n",
    "                index_marker += 1\n",
    "\n",
    "        plt.yticks(rotation=45)\n",
    "        plt.legend(loc=\"upper left\", framealpha=0, prop={\"family\": \"Times New Roman\", \"size\": 10})\n",
    "        subplot_index += 1\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"./{}/{}_{}.pdf\".format(config, config, group_name), bbox_inches='tight')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# merge those\n",
    "\n",
    "from PyPDF2 import PdfMerger\n",
    "\n",
    "def merge_pdfs(pdf_paths, output_path):\n",
    "    merger = PdfMerger()\n",
    "    for pdf_path in pdf_paths:\n",
    "        merger.append(pdf_path)\n",
    "    merger.write(output_path)\n",
    "    merger.close()\n",
    "\n",
    "def search_for_pdfs(folder_path):\n",
    "    pdf_files = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.pdf'):\n",
    "                pdf_files.append(os.path.join(root, file))\n",
    "    return pdf_files\n",
    "\n",
    "folder_path = \"./{}\".format(config)\n",
    "pdf_files = search_for_pdfs(folder_path)\n",
    "output_path = \"./{}/{}_merged_plots.pdf\".format(config, config)  # Output path for merged PDF\n",
    "\n",
    "merge_pdfs(pdf_files, output_path)\n",
    "print(\"Done merging...\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
